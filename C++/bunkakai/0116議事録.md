# 分科会議事録

## 3章

C++/SQLServerについてこれを描く
国内の使用状況
所属における使用状況
特異な処理
苦手な処理
継続的なメンテナンス
開発人材の確保

今現時点で分かっている結果をまとめて送る


## 現時点で分かっていること

### C++

#### 結果

* 実行時間は早い。
  * 他のツールと違って、csvを1行ずつ読んでいくため、必要なメモリのサイズが小さい。（プログラム例を図示）
* 実行時間の大半は、型変換によるもの。（プログラム例を図示）
  * SSDの台頭により、HDDを使っていた時代と比較し、データの入出力に係る時間が大幅に減っている可能性がある。
  * 逆に言えば、データの入出力に時間がかかる場合、ハードをHDDからSSDに変更することを検討する必要性が高い。
* 毎回実行しなおす必要があるため、毎回読み込みに時間がかかる（プログラム例を図示）
  * 他の言語と違い、C++は原則、実行中にプログラムを書き換えることができない。(JupyterNotebookのような対話的なプログラミングができない)
  * したがって、計測モデルを少しずついじりながら結果を比べる、といった使い方には不向き。

#### 課題と解決策

* 型変換が遅い
  * 読み込みの大半の時間がかかっている型変換について、前処理として型変換をあらかじめすることで回避可能
  * 型変換後のデータをバイナリデータとして保存しておく方法が考えられる。（プログラム例を図示）
  * デメリットとして、扱いが非常に難しい。10行10列目を読んでいるつもりが、11行1列目を読んでしまっていた、ということもありうる。
  * 他に、SQLServerの動作が早いことに目を付け、SQLServerをC++から実行することで処理速度を上げる方法が考えられる。
    * SQLServerとの連携は難しいが、バイナリデータを直接扱うよりは簡単
* 実行しながら対話的にプログラムを書き換えたい
  * JupyterNotebook等でC++を動かす方法が存在する。
  * Cling等の、C++のインタプリタ実装を用いることで、対話的なプログラミングが可能となる。
  * 実測していないが、インタプリタは通常動作が遅いので、C++のメリットである計算が早い点を生かせない可能性が高い。
    * Pythonであれば、和文の文献は多くないものの、インタプリタ実装しつつ、必要な個所はコンパイルすることが可能である。

### Python

#### 結果

* Pandasは、小さいサイズは読むことができたが、大きいサイズは読み込むことすらできなかった
  * 一度にcsv全体をメモリに取り込む仕様のため、メモリエラーが発生（プログラム例を図示）
* csvモジュールは、適切に実装することで、大きいサイズでも読み込むことができた。
  * 一行ずつcsvを読み込んでいる（プログラム例を図示）
  * ただし、一度にまとめてcsvを読んでしまうと、エラー（プログラム例を図示）
* Pandas+Pickle化は、Pickle化できる場合は高速だが、メモリエラーが生じやすい。
  * そもそもPandasで取り込むことすらできないので、当然、Pickle化もできない
* 実行時間は、C++よりは遅い
  * インタプリタ言語のため

#### 課題と解決策

* Pandasで大きいデータを読むことができない
  * （富田さんお願いします）
* 実行時間が遅い
  * インタプリタであるために遅いので、コンパイルすることである程度対応可能
  * nambdaモジュールのjit(実行時コンパイル)や、Cython(C/C++に変換してから実行する)、PyPy(PythonのJITコンパイル版)等がある（プログラム例を図示）
  * 行列計算等の、数学的な処理であれば、NumPyモジュール等を使うことで高速化される
  * ただし、いずれもできる処理・できない処理があり、癖がある。
    * 重たい計算をPythonにさせるのであれば、今後の技術進歩のキャッチアップが必要となる。（計算速度は、プログラミング言語の開発者に金が積まれれば積まれるほど高度なロジックが実装され、早くなる）
  * Python高速化については、文献もそこまで多くないか
    * 発表の場で初めて「JIT」というキーワードを聞いた方も多いはず。

### SQLServer

#### 結果

* 読み込みも、計算も高速
* SQLServerは、メモリとSSD(HDD)をバランスよく使うため、メモリに収まりきらないデータを入れてもバランスよくメモリを使ってくれる。そのため、メモリエラーが生じにくい
* ただし、複雑な計算（数値計算）は難しい
  * SQLはデータ加工に特化したツールであるため、収益性の計算等を実装するのは困難。
  * 必要なデータだけに抽出したり、データをきれいに(クレンジング)するのには向いている。

#### 課題と解決策

* 複雑な計算はできない
  * 鈴木さんお願いします

### Excel

#### 結果

* 普通にcsvを開くことはできない
  * 600万行あり、Excelは100万行以上のデータを開けないため
* PowerQueryを経由した場合、小さいサイズを読むことはできたが、大きいサイズは読み込めなかった
  * 小さいサイズの場合も、他ツールと比較し処理時間は遅い。

#### 課題と解決策

* 必要なデータだけに限定して処理する
  * 例えば、5000シナリオ1200か月=600万行のデータを、500シナリオ60年=30000行のデータに絞って検証する等
